import sys
import os
# ğŸ”§ Ajout du dossier parent pour les imports depuis app/
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))


from langchain_community.document_loaders import PyPDFLoader
import tempfile
import streamlit as st
import traceback
from app import config
from app.utils.utils import load_api_key  
from app.utils.utils_streamlit import display_model_config
from app.rag_engine import RAGPipeline, FAISSRetriever, TemporaryFAISSRetriever,OpenAILLM


# ğŸ¨ Configuration de la page
st.set_page_config(
    page_title="RAG Assistant",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ğŸŒŸ Titre principal
st.title("ğŸ” RAG Chatbot - Question / RÃ©ponse augmentÃ©e")
st.markdown("""
Pose ta question ci-dessous âœ‰ï¸
Le modÃ¨le te rÃ©pondra Ã  partir des documents PDF que tu as indexÃ©s.
""")

# ğŸ§  Barre latÃ©rale : ClÃ© API et paramÃ¨tres
with st.sidebar:
    # âš™ï¸ ParamÃ¨tres du modÃ¨le (directement visibles)
    model, temperature, k = display_model_config("global")

     # ğŸ”‘ ClÃ© OpenAI personnalisÃ©e
    user_api_key = st.text_input(
        "ğŸ”‘ Ta clÃ© OpenAI (optionnelle)",
        type="password",
        placeholder="sk-...",
        # help="Elle sera utilisÃ©e Ã  la place de celle du .env si renseignÃ©e.",
    )


# ğŸ–‹ï¸ EntrÃ©e utilisateur : Question
question = st.text_input(
    "â“ Ta question :",
    placeholder="Ex: Ask me ! The World is yours."
)



# ğŸš€ Bouton d'envoi de la question
if st.button("ğŸ“¤ Poser la question") and question:
    with st.spinner("ğŸ¤– Le modÃ¨le rÃ©flÃ©chit..."):
        try:
            # load the key 
            load_api_key(user_api_key)

            # Initialise les composants
            llm = OpenAILLM(model_name=model, temperature=temperature, user_api_key=user_api_key)
            retriever = FAISSRetriever(persist_path=config.VECTORSTORE_PATH)
            pipeline = RAGPipeline(retriever=retriever, llm=llm)

            # Pose la question
            result = pipeline.ask(question, k=k)

            # ğŸ”¸ Layout en deux colonnes
            col_left, col_right = st.columns([2, 1])

            # ğŸ”¸ Colonne gauche : rÃ©ponse
            with col_left:
                st.success("âœ… RÃ©ponse :")
                st.markdown(result["result"])

            # ğŸ”¸ Colonne droite : documents sources
            with col_right:
                st.markdown("""
                #### ğŸ“„ Sources documentaires utilisÃ©es
                """)
                if result.get("source_documents"):
                    for i, doc in enumerate(result["source_documents"], start=1):
                        title = doc.metadata.get("source", "Document inconnu")
                        page = doc.metadata.get("page", "?")
                        content = doc.page_content[:500] + "..."

                        with st.expander(f"ğŸ“„ {title} (page {page})"):
                            st.markdown(content)
                else:
                    st.info("Aucune source documentaire n'a Ã©tÃ© retournÃ©e.")

        except Exception as e:
            st.error(f"âŒ Une erreur est survenue : {e}")
            st.code(traceback.format_exc(), language="python")


# ğŸ“ TÃ©lÃ©versement de fichiers temporaires
st.warning("âš ï¸ Ce document ne sera **pas sauvegardÃ©**. Il est utilisÃ© uniquement pendant cette session.")
uploaded_files = st.file_uploader("ğŸ“ TÃ©lÃ©verse un fichier PDF pour faire du RAG temporaire :", 
                                   type=["pdf"], 
                                   accept_multiple_files=True)

# ğŸ“„ Extraction des documents uploadÃ©s
session_docs = []

if uploaded_files:
    for uploaded_file in uploaded_files:
        # CrÃ©er un fichier temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        # Charger avec LangChain
        loader = PyPDFLoader(tmp_path)
        docs = loader.load()

        # Ajouter la source pour affichage futur
        for doc in docs:
            doc.metadata["source"] = uploaded_file.name
        session_docs.extend(docs)

        # Supprimer le fichier temporaire une fois chargÃ©
        os.remove(tmp_path)

    st.success(f"âœ… {len(session_docs)} page(s) PDF chargÃ©e(s) depuis les documents uploadÃ©s.")

if session_docs:
    st.divider()
    st.markdown("## ğŸ’¬ Pose ta question sur le document uploadÃ©")

    question = st.text_input("â“ Ta question (document temporaire)")

    if st.button("ğŸ“¤ Interroger le document") and question:
        with st.spinner("ğŸ’¡ GÃ©nÃ©ration en cours..."):
            try:
                
                # load the key 
                load_api_key(user_api_key)
                # Pour le mode "temporaire"
                llm = OpenAILLM(model_name=model, temperature=temperature, user_api_key=user_api_key)
                retriever = TemporaryFAISSRetriever(docs=session_docs)
                pipeline = RAGPipeline(retriever=retriever, llm=llm)
                result = pipeline.ask(question, k=k)

                st.success("ğŸ§  RÃ©ponse :")
                st.markdown(result["result"])

                st.markdown("ğŸ“ **Sources :**")
                for doc in result["source_documents"]:
                    st.markdown(f"- `{doc.metadata['source']}`")

            except Exception as e:
                st.error(f"âŒ Erreur pendant l'exÃ©cution : {e}")


# ğŸ¡ Footer
st.markdown(
    "<div style='text-align: center; padding-top: 2rem;'>"
    "<sub>ğŸš€ CrÃ©Ã© avec ğŸ’ª par <b>Charif EL JAZOULI</b> â€¢ "
    "<a href='https://github.com/ton-lien-github' target='_blank'>GitHub</a></sub>"
    "</div>",
    unsafe_allow_html=True
)